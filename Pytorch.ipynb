{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlQ94gT4GyKz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "from collections import OrderedDict\n",
        "from collections import defaultdict\n",
        "from torchsummary import summary\n",
        "from torch import nn\n",
        "from torch.quantization import quantize_fx\n",
        "import copy\n",
        "\n",
        "\n",
        "torch.set_printoptions(profile=\"full\")\n",
        "import numpy as np\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "#torch.set_default_dtype(torch.quint8)\n",
        "\n",
        "pd.set_option('display.max_columns', None)  # or 1000\n",
        "pd.set_option('display.max_rows', None)  # or 1000\n",
        "pd.set_option('display.max_colwidth', None)  # or 199"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfcHveXKv8Db",
        "outputId": "93f48f7d-97a8-481b-f638-afd74edb2f31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks')\n",
        "cwd= os.getcwd()\n",
        "print (cwd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUnzJyEMHnQe"
      },
      "outputs": [],
      "source": [
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/dogs-vs-cats\"\n",
        "os.chdir(path)\n",
        "train_df = pd.DataFrame(columns=[\"img_name\",\"label\"])\n",
        "train_df[\"img_name\"] = os.listdir(\"train/\")\n",
        "for idx, i in enumerate(os.listdir(\"train/\")):\n",
        "    if \"cat\" in i:\n",
        "        train_df[\"label\"][idx] = 0\n",
        "    if \"dog\" in i:\n",
        "        train_df[\"label\"][idx] = 1\n",
        "\n",
        "train_df.to_csv (r'train_csv.csv', index = False, header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vdy9awh2uNnY"
      },
      "outputs": [],
      "source": [
        "class CatsAndDogsDataset(Dataset):\n",
        "    def __init__(self, root_dir, annotation_file, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.annotations = pd.read_csv(annotation_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_id = self.annotations.iloc[index, 0]\n",
        "        img = Image.open(os.path.join(self.root_dir, img_id)).convert(\"RGB\")\n",
        "        y_label = torch.tensor(float(self.annotations.iloc[index, 1]))\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return (img, y_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIqGIb6jx2JV",
        "outputId": "82ca3744-93bf-4321-95c7-729c0b0916a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AlexNet',\n",
              " 'AlexNet_Weights',\n",
              " 'ConvNeXt',\n",
              " 'ConvNeXt_Base_Weights',\n",
              " 'ConvNeXt_Large_Weights',\n",
              " 'ConvNeXt_Small_Weights',\n",
              " 'ConvNeXt_Tiny_Weights',\n",
              " 'DenseNet',\n",
              " 'DenseNet121_Weights',\n",
              " 'DenseNet161_Weights',\n",
              " 'DenseNet169_Weights',\n",
              " 'DenseNet201_Weights',\n",
              " 'EfficientNet',\n",
              " 'EfficientNet_B0_Weights',\n",
              " 'EfficientNet_B1_Weights',\n",
              " 'EfficientNet_B2_Weights',\n",
              " 'EfficientNet_B3_Weights',\n",
              " 'EfficientNet_B4_Weights',\n",
              " 'EfficientNet_B5_Weights',\n",
              " 'EfficientNet_B6_Weights',\n",
              " 'EfficientNet_B7_Weights',\n",
              " 'EfficientNet_V2_L_Weights',\n",
              " 'EfficientNet_V2_M_Weights',\n",
              " 'EfficientNet_V2_S_Weights',\n",
              " 'GoogLeNet',\n",
              " 'GoogLeNetOutputs',\n",
              " 'GoogLeNet_Weights',\n",
              " 'Inception3',\n",
              " 'InceptionOutputs',\n",
              " 'Inception_V3_Weights',\n",
              " 'MNASNet',\n",
              " 'MNASNet0_5_Weights',\n",
              " 'MNASNet0_75_Weights',\n",
              " 'MNASNet1_0_Weights',\n",
              " 'MNASNet1_3_Weights',\n",
              " 'MaxVit',\n",
              " 'MaxVit_T_Weights',\n",
              " 'MobileNetV2',\n",
              " 'MobileNetV3',\n",
              " 'MobileNet_V2_Weights',\n",
              " 'MobileNet_V3_Large_Weights',\n",
              " 'MobileNet_V3_Small_Weights',\n",
              " 'RegNet',\n",
              " 'RegNet_X_16GF_Weights',\n",
              " 'RegNet_X_1_6GF_Weights',\n",
              " 'RegNet_X_32GF_Weights',\n",
              " 'RegNet_X_3_2GF_Weights',\n",
              " 'RegNet_X_400MF_Weights',\n",
              " 'RegNet_X_800MF_Weights',\n",
              " 'RegNet_X_8GF_Weights',\n",
              " 'RegNet_Y_128GF_Weights',\n",
              " 'RegNet_Y_16GF_Weights',\n",
              " 'RegNet_Y_1_6GF_Weights',\n",
              " 'RegNet_Y_32GF_Weights',\n",
              " 'RegNet_Y_3_2GF_Weights',\n",
              " 'RegNet_Y_400MF_Weights',\n",
              " 'RegNet_Y_800MF_Weights',\n",
              " 'RegNet_Y_8GF_Weights',\n",
              " 'ResNeXt101_32X8D_Weights',\n",
              " 'ResNeXt101_64X4D_Weights',\n",
              " 'ResNeXt50_32X4D_Weights',\n",
              " 'ResNet',\n",
              " 'ResNet101_Weights',\n",
              " 'ResNet152_Weights',\n",
              " 'ResNet18_Weights',\n",
              " 'ResNet34_Weights',\n",
              " 'ResNet50_Weights',\n",
              " 'ShuffleNetV2',\n",
              " 'ShuffleNet_V2_X0_5_Weights',\n",
              " 'ShuffleNet_V2_X1_0_Weights',\n",
              " 'ShuffleNet_V2_X1_5_Weights',\n",
              " 'ShuffleNet_V2_X2_0_Weights',\n",
              " 'SqueezeNet',\n",
              " 'SqueezeNet1_0_Weights',\n",
              " 'SqueezeNet1_1_Weights',\n",
              " 'SwinTransformer',\n",
              " 'Swin_B_Weights',\n",
              " 'Swin_S_Weights',\n",
              " 'Swin_T_Weights',\n",
              " 'Swin_V2_B_Weights',\n",
              " 'Swin_V2_S_Weights',\n",
              " 'Swin_V2_T_Weights',\n",
              " 'VGG',\n",
              " 'VGG11_BN_Weights',\n",
              " 'VGG11_Weights',\n",
              " 'VGG13_BN_Weights',\n",
              " 'VGG13_Weights',\n",
              " 'VGG16_BN_Weights',\n",
              " 'VGG16_Weights',\n",
              " 'VGG19_BN_Weights',\n",
              " 'VGG19_Weights',\n",
              " 'ViT_B_16_Weights',\n",
              " 'ViT_B_32_Weights',\n",
              " 'ViT_H_14_Weights',\n",
              " 'ViT_L_16_Weights',\n",
              " 'ViT_L_32_Weights',\n",
              " 'VisionTransformer',\n",
              " 'Weights',\n",
              " 'WeightsEnum',\n",
              " 'Wide_ResNet101_2_Weights',\n",
              " 'Wide_ResNet50_2_Weights',\n",
              " '_GoogLeNetOutputs',\n",
              " '_InceptionOutputs',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_api',\n",
              " '_meta',\n",
              " '_utils',\n",
              " 'alexnet',\n",
              " 'convnext',\n",
              " 'convnext_base',\n",
              " 'convnext_large',\n",
              " 'convnext_small',\n",
              " 'convnext_tiny',\n",
              " 'densenet',\n",
              " 'densenet121',\n",
              " 'densenet161',\n",
              " 'densenet169',\n",
              " 'densenet201',\n",
              " 'detection',\n",
              " 'efficientnet',\n",
              " 'efficientnet_b0',\n",
              " 'efficientnet_b1',\n",
              " 'efficientnet_b2',\n",
              " 'efficientnet_b3',\n",
              " 'efficientnet_b4',\n",
              " 'efficientnet_b5',\n",
              " 'efficientnet_b6',\n",
              " 'efficientnet_b7',\n",
              " 'efficientnet_v2_l',\n",
              " 'efficientnet_v2_m',\n",
              " 'efficientnet_v2_s',\n",
              " 'get_model',\n",
              " 'get_model_builder',\n",
              " 'get_model_weights',\n",
              " 'get_weight',\n",
              " 'googlenet',\n",
              " 'inception',\n",
              " 'inception_v3',\n",
              " 'list_models',\n",
              " 'maxvit',\n",
              " 'maxvit_t',\n",
              " 'mnasnet',\n",
              " 'mnasnet0_5',\n",
              " 'mnasnet0_75',\n",
              " 'mnasnet1_0',\n",
              " 'mnasnet1_3',\n",
              " 'mobilenet',\n",
              " 'mobilenet_v2',\n",
              " 'mobilenet_v3_large',\n",
              " 'mobilenet_v3_small',\n",
              " 'mobilenetv2',\n",
              " 'mobilenetv3',\n",
              " 'optical_flow',\n",
              " 'quantization',\n",
              " 'regnet',\n",
              " 'regnet_x_16gf',\n",
              " 'regnet_x_1_6gf',\n",
              " 'regnet_x_32gf',\n",
              " 'regnet_x_3_2gf',\n",
              " 'regnet_x_400mf',\n",
              " 'regnet_x_800mf',\n",
              " 'regnet_x_8gf',\n",
              " 'regnet_y_128gf',\n",
              " 'regnet_y_16gf',\n",
              " 'regnet_y_1_6gf',\n",
              " 'regnet_y_32gf',\n",
              " 'regnet_y_3_2gf',\n",
              " 'regnet_y_400mf',\n",
              " 'regnet_y_800mf',\n",
              " 'regnet_y_8gf',\n",
              " 'resnet',\n",
              " 'resnet101',\n",
              " 'resnet152',\n",
              " 'resnet18',\n",
              " 'resnet34',\n",
              " 'resnet50',\n",
              " 'resnext101_32x8d',\n",
              " 'resnext101_64x4d',\n",
              " 'resnext50_32x4d',\n",
              " 'segmentation',\n",
              " 'shufflenet_v2_x0_5',\n",
              " 'shufflenet_v2_x1_0',\n",
              " 'shufflenet_v2_x1_5',\n",
              " 'shufflenet_v2_x2_0',\n",
              " 'shufflenetv2',\n",
              " 'squeezenet',\n",
              " 'squeezenet1_0',\n",
              " 'squeezenet1_1',\n",
              " 'swin_b',\n",
              " 'swin_s',\n",
              " 'swin_t',\n",
              " 'swin_transformer',\n",
              " 'swin_v2_b',\n",
              " 'swin_v2_s',\n",
              " 'swin_v2_t',\n",
              " 'vgg',\n",
              " 'vgg11',\n",
              " 'vgg11_bn',\n",
              " 'vgg13',\n",
              " 'vgg13_bn',\n",
              " 'vgg16',\n",
              " 'vgg16_bn',\n",
              " 'vgg19',\n",
              " 'vgg19_bn',\n",
              " 'video',\n",
              " 'vision_transformer',\n",
              " 'vit_b_16',\n",
              " 'vit_b_32',\n",
              " 'vit_h_14',\n",
              " 'vit_l_16',\n",
              " 'vit_l_32',\n",
              " 'wide_resnet101_2',\n",
              " 'wide_resnet50_2']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "dir(models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-bHrYJY6bMq",
        "outputId": "fdddc23d-3934-4ed1-c85f-dbf4f4f40cd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# First, load the model\n",
        "\n",
        "\n",
        "resnet = models.resnet34(pretrained=True)\n",
        "resnet.name = 'resnet'\n",
        "alexnet = models.alexnet(pretrained=True)\n",
        "alexnet.name = 'alexnet'\n",
        "vgg19 = models.vgg19(pretrained=True)\n",
        "vgg19.name = 'vgg19'\n",
        "\n",
        "\n",
        "models_list = [resnet]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zX8rywKXFDU1"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        " transforms.Resize(256),\n",
        " transforms.CenterCrop(224),\n",
        " transforms.ToTensor(),\n",
        " transforms.Normalize(\n",
        " mean=[0.485, 0.456, 0.406],\n",
        " std=[0.229, 0.224, 0.225]\n",
        " )])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvrSCHRwHrAE",
        "outputId": "ecd19d3f-b5fa-4e68-d540-a1b56d60cba9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (3): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (3): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (4): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (5): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "for model in models_list:\n",
        "  print(model)\n",
        "  model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecGvTyShH4ia"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(\"/content/drive/MyDrive/Colab Notebooks\",'imagenet_classes.txt')) as f:\n",
        "  labels = [line.strip() for line in f.readlines()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TowZdmIrFucC"
      },
      "outputs": [],
      "source": [
        "#img=Image.open(os.path.join(\"/content/drive/MyDrive/Colab Notebooks\", \"dog.jpg\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4sRelVteVlE"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/Colab Notebooks/dogs-vs-cats/test1\"\n",
        "def image_loader(image_name):\n",
        "    \"\"\"load image, returns cuda tensor\"\"\"\n",
        "    image = Image.open(os.path.join(path, image_name))\n",
        "    img_t = transform(image)\n",
        "    batch_t1 = torch.unsqueeze(img_t, 0)\n",
        "    return batch_t1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Colab Notebooks/dogs-vs-cats/test1\"\n",
        "os.chdir(path)\n",
        "cwd= os.getcwd()\n",
        "print(cwd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXlkDYDMY14m",
        "outputId": "c59bce03-178b-43d5-bb2d-2e4f954503b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/dogs-vs-cats/test1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPe_BQ9sNogv"
      },
      "outputs": [],
      "source": [
        "def rep_dataset():\n",
        "    \"\"\"Generator function to produce representative dataset for post-training quantization.\"\"\"\n",
        "\n",
        "    # Use a few samples from the training set.\n",
        "    for _ in range(100):\n",
        "        img = iter(train_loader).next()[0].numpy()\n",
        "        img = [(img.astype(np.float32))]\n",
        "        yield img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byu2gRNHNpRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a21b2953-6b43-4909-cad7-604010ace2b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# define a floating point model where some layers could be statically quantized\n",
        "class M(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # QuantStub converts tensors from floating point to quantized\n",
        "        self.quant = torch.ao.quantization.QuantStub()\n",
        "        self.conv = torch.nn.Conv2d(1, 1, 1)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        # DeQuantStub converts tensors from quantized to floating point\n",
        "        self.dequant = torch.ao.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # manually specify where tensors will be converted from floating\n",
        "        # point to quantized in the quantized model\n",
        "        x = self.quant(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.relu(x)\n",
        "        # manually specify where tensors will be converted from quantized\n",
        "        # to floating point in the quantized model\n",
        "        x = self.dequant(x)\n",
        "        return x\n",
        "\n",
        "# create a model instance\n",
        "model_fp32 = M()\n",
        "\n",
        "# model must be set to eval mode for static quantization logic to work\n",
        "model_fp32.eval()\n",
        "\n",
        "# attach a global qconfig, which contains information about what kind\n",
        "# of observers to attach. Use 'x86' for server inference and 'qnnpack'\n",
        "# for mobile inference. Other quantization configurations such as selecting\n",
        "# symmetric or asymmetric quantization and MinMax or L2Norm calibration techniques\n",
        "# can be specified here.\n",
        "# Note: the old 'fbgemm' is still available but 'x86' is the recommended default\n",
        "# for server inference.\n",
        "# model_fp32.qconfig = torch.ao.quantization.get_default_qconfig('fbgemm')\n",
        "model_fp32.qconfig = torch.ao.quantization.get_default_qconfig('x86')\n",
        "\n",
        "# Fuse the activations to preceding layers, where applicable.\n",
        "# This needs to be done manually depending on the model architecture.\n",
        "# Common fusions include `conv + relu` and `conv + batchnorm + relu`\n",
        "model_fp32_fused = torch.ao.quantization.fuse_modules(model_fp32, [['conv', 'relu']])\n",
        "\n",
        "# Prepare the model for static quantization. This inserts observers in\n",
        "# the model that will observe activation tensors during calibration.\n",
        "model_fp32_prepared = torch.ao.quantization.prepare(model_fp32_fused)\n",
        "\n",
        "# calibrate the prepared model to determine quantization parameters for activations\n",
        "# in a real world setting, the calibration would be done with a representative dataset\n",
        "input_fp32 = torch.randn(4, 1, 4, 4)\n",
        "model_fp32_prepared(input_fp32)\n",
        "\n",
        "# Convert the observed model to a quantized model. This does several things:\n",
        "# quantizes the weights, computes and stores the scale and bias value to be\n",
        "# used with each activation tensor, and replaces key operators with quantized\n",
        "# implementations.\n",
        "model_int8 = torch.ao.quantization.convert(model_fp32_prepared)\n",
        "\n",
        "# run the model, relevant calculations will happen in int8\n",
        "res = model_int8(input_fp32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flYRnspNNwSS",
        "outputId": "40faea76-85a5-4889-8229-d6af88a25d36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M(\n",
            "  (quant): QuantStub()\n",
            "  (conv): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (relu): ReLU()\n",
            "  (dequant): DeQuantStub()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "models_quantized_list = []\n",
        "for model in models_list:\n",
        "  res_model = M()\n",
        "  print(res_model)\n",
        "  res_model.name = model.name + '_quantized'\n",
        "  models_quantized_list.append(res_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzcrvuLbNPQC",
        "outputId": "99e8e20f-48f5-4dc6-e68d-a03d7b24971c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1\n",
            "bn1\n",
            "relu\n",
            "maxpool\n",
            "layer1\n",
            "layer2\n",
            "layer3\n",
            "layer4\n",
            "avgpool\n",
            "fc\n"
          ]
        }
      ],
      "source": [
        "def create_hooks(model_name,layer_name):\n",
        "  selected_out = OrderedDict()\n",
        "  selected_input = OrderedDict()\n",
        "  return [selected_out, selected_input]\n",
        "\n",
        "def forward_hook(layer_name, inputstr, outputstr):\n",
        "        def hook(module, input, output):\n",
        "            #selected_out[layer_name] = output\n",
        "            #selected_input[layer_name] = input\n",
        "            data[inputstr][layer_name] = input\n",
        "            data[outputstr][layer_name] = output\n",
        "\n",
        "            #df2 = {'layer': 'layer_name', 'input_size': input[0].size(), 'output_size': output.data.size(), 'output_norm':output.data.norm()}\n",
        "\n",
        "        return hook\n",
        "\n",
        "\n",
        "fhooks = []\n",
        "\n",
        "data = defaultdict(dict)\n",
        "for model in models_quantized_list:\n",
        "  for i in ['input', 'output']:\n",
        "    data[\"_\".join([model.name, i])] = OrderedDict()\n",
        "\n",
        "for model in models_list:\n",
        "  for name, layer in model._modules.items():\n",
        "    print(name)\n",
        "    #inputarr, outputarr = create_hooks(model.name, name)\n",
        "    inputstr = model.name + '_' + 'input'\n",
        "    outputstr = model.name + '_' + 'output'\n",
        "\n",
        "    fhooks.append(layer.register_forward_hook(forward_hook(name, inputstr, outputstr)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7_pU9ozJMjg"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/Colab Notebooks/dogs-vs-cats\"\n",
        "os.chdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS1eF-AIBI9k",
        "outputId": "b8287201-ad6f-4efb-e2e1-77c543ee2d5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10601\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "learning_rate = 0.00001\n",
        "train_CNN = False\n",
        "batch_size = 32\n",
        "shuffle = True\n",
        "pin_memory = True\n",
        "num_workers = 0\n",
        "dataset = CatsAndDogsDataset(\"train\",\"train_csv.csv\",transform=transform)\n",
        "print(len(dataset))\n",
        "#train_size = int(0.8 * len(dataset))\n",
        "#train_set= torch.utils.data.random_split(dataset, [train_size])\n",
        "train_loader = DataLoader(dataset=dataset, shuffle=shuffle, batch_size=batch_size,num_workers=num_workers,pin_memory=pin_memory)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVN14U7zdF1P",
        "outputId": "a497a488-30b3-4460-9618-34007a85af11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/dogs-vs-cats/test1\n"
          ]
        }
      ],
      "source": [
        "path = \"/content/drive/MyDrive/Colab Notebooks/dogs-vs-cats/test1\"\n",
        "os.chdir(path)\n",
        "cwd= os.getcwd()\n",
        "print(cwd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB3GspewfHtx",
        "outputId": "36aeaba3-2be9-40ee-a8ee-2c086422e635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running test for model list  resnet\n",
            "torch.Size([1, 1000])\n",
            "11455.jpg tabby, tabby cat 57.0185432434082\n",
            "torch.Size([1, 1000])\n",
            "11459.jpg Chihuahua 97.77523803710938\n",
            "torch.Size([1, 1000])\n",
            "11564.jpg Egyptian cat 60.01301574707031\n",
            "torch.Size([1, 1000])\n",
            "11505.jpg lynx, catamount 60.65275192260742\n",
            "torch.Size([1, 1000])\n",
            "11514.jpg whippet 22.04637336730957\n",
            "torch.Size([1, 1000])\n",
            "11535.jpg Rhodesian ridgeback 88.1002426147461\n",
            "torch.Size([1, 1000])\n",
            "11546.jpg Egyptian cat 30.778223037719727\n",
            "torch.Size([1, 1000])\n",
            "11504.jpg Egyptian cat 27.995555877685547\n",
            "torch.Size([1, 1000])\n",
            "11561.jpg Shetland sheepdog, Shetland sheep dog, Shetland 45.047874450683594\n",
            "torch.Size([1, 1000])\n",
            "11508.jpg tabby, tabby cat 67.6646499633789\n"
          ]
        }
      ],
      "source": [
        "def runtest(model):\n",
        "  for idx, i in enumerate(os.listdir(cwd)[:10] ):\n",
        "    batch_t = image_loader(i)\n",
        "    out = model(batch_t)\n",
        "    print(out.shape)\n",
        "    _, index = torch.max(out, 1)\n",
        "    percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "    print(i, labels[index[0]], percentage[index[0]].item())\n",
        "\n",
        "for model in models_list:\n",
        "  print('running test for model list ', model.name)\n",
        "  runtest(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wckkonS6PFvU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52f130d9-a89c-44e3-d4c7-3c42ecc01da9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model is  resnet_quantized_input\n",
            "model is  resnet_quantized_output\n",
            "model is  resnet_input\n",
            "layer is  conv1\n",
            "layer is  bn1\n",
            "layer is  relu\n",
            "layer is  maxpool\n",
            "layer is  layer1\n",
            "layer is  layer2\n",
            "layer is  layer3\n",
            "layer is  layer4\n",
            "layer is  avgpool\n",
            "layer is  fc\n",
            "model is  resnet_output\n",
            "layer is  conv1\n",
            "layer is  bn1\n",
            "layer is  relu\n",
            "layer is  maxpool\n",
            "layer is  layer1\n",
            "layer is  layer2\n",
            "layer is  layer3\n",
            "layer is  layer4\n",
            "layer is  avgpool\n",
            "layer is  fc\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from torch.fx import symbolic_trace\n",
        "\n",
        "for key, value in data.items():\n",
        "  dir_path = \"/content/drive/MyDrive/Colab Notebooks/\" + key\n",
        "  if not os.path.isdir(dir_path):\n",
        "    os.makedirs(dir_path)\n",
        "  print(\"model is \", key)\n",
        "  for k1, val1 in data[key].items():\n",
        "    file_name = k1 + '.csv'\n",
        "    print(\"layer is \", k1)\n",
        "    try:\n",
        "\n",
        "      with open(os.path.join(dir_path,file_name), \"w\") as csv_file:\n",
        "        csvwriter = csv.writer(csv_file)\n",
        "        csvwriter.writerow(val1)\n",
        "\n",
        "    except Exception as e:\n",
        "      substring = \"TraceError\"\n",
        "      if substring in str(e):\n",
        "        print(\"Proxy Object Error, continuing\")\n",
        "      else:\n",
        "        print(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNc2KP67RPXY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Forth, print the top 5 classes predicted by the model\n",
        "#_, indices = torch.sort(out, descending=True)\n",
        "#percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "#[(labels[idx], percentage[idx].item()) for idx in indices[0][:5]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYco-Sy1Aphx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2db1a8de-44e0-4166-d645-c97e42c248ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
            "             ReLU-21           [-1, 64, 56, 56]               0\n",
            "           Conv2d-22           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-23           [-1, 64, 56, 56]             128\n",
            "             ReLU-24           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-25           [-1, 64, 56, 56]               0\n",
            "           Conv2d-26          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-27          [-1, 128, 28, 28]             256\n",
            "             ReLU-28          [-1, 128, 28, 28]               0\n",
            "           Conv2d-29          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-30          [-1, 128, 28, 28]             256\n",
            "           Conv2d-31          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-36          [-1, 128, 28, 28]             256\n",
            "             ReLU-37          [-1, 128, 28, 28]               0\n",
            "           Conv2d-38          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-39          [-1, 128, 28, 28]             256\n",
            "             ReLU-40          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-41          [-1, 128, 28, 28]               0\n",
            "           Conv2d-42          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-43          [-1, 128, 28, 28]             256\n",
            "             ReLU-44          [-1, 128, 28, 28]               0\n",
            "           Conv2d-45          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-46          [-1, 128, 28, 28]             256\n",
            "             ReLU-47          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-48          [-1, 128, 28, 28]               0\n",
            "           Conv2d-49          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
            "             ReLU-51          [-1, 128, 28, 28]               0\n",
            "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
            "             ReLU-54          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-55          [-1, 128, 28, 28]               0\n",
            "           Conv2d-56          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-57          [-1, 256, 14, 14]             512\n",
            "             ReLU-58          [-1, 256, 14, 14]               0\n",
            "           Conv2d-59          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-60          [-1, 256, 14, 14]             512\n",
            "           Conv2d-61          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-62          [-1, 256, 14, 14]             512\n",
            "             ReLU-63          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-64          [-1, 256, 14, 14]               0\n",
            "           Conv2d-65          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-66          [-1, 256, 14, 14]             512\n",
            "             ReLU-67          [-1, 256, 14, 14]               0\n",
            "           Conv2d-68          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-69          [-1, 256, 14, 14]             512\n",
            "             ReLU-70          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-71          [-1, 256, 14, 14]               0\n",
            "           Conv2d-72          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-73          [-1, 256, 14, 14]             512\n",
            "             ReLU-74          [-1, 256, 14, 14]               0\n",
            "           Conv2d-75          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-76          [-1, 256, 14, 14]             512\n",
            "             ReLU-77          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-78          [-1, 256, 14, 14]               0\n",
            "           Conv2d-79          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-80          [-1, 256, 14, 14]             512\n",
            "             ReLU-81          [-1, 256, 14, 14]               0\n",
            "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
            "             ReLU-84          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-85          [-1, 256, 14, 14]               0\n",
            "           Conv2d-86          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-87          [-1, 256, 14, 14]             512\n",
            "             ReLU-88          [-1, 256, 14, 14]               0\n",
            "           Conv2d-89          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-90          [-1, 256, 14, 14]             512\n",
            "             ReLU-91          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-92          [-1, 256, 14, 14]               0\n",
            "           Conv2d-93          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-94          [-1, 256, 14, 14]             512\n",
            "             ReLU-95          [-1, 256, 14, 14]               0\n",
            "           Conv2d-96          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-97          [-1, 256, 14, 14]             512\n",
            "             ReLU-98          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-99          [-1, 256, 14, 14]               0\n",
            "          Conv2d-100            [-1, 512, 7, 7]       1,179,648\n",
            "     BatchNorm2d-101            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-102            [-1, 512, 7, 7]               0\n",
            "          Conv2d-103            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-104            [-1, 512, 7, 7]           1,024\n",
            "          Conv2d-105            [-1, 512, 7, 7]         131,072\n",
            "     BatchNorm2d-106            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-107            [-1, 512, 7, 7]               0\n",
            "      BasicBlock-108            [-1, 512, 7, 7]               0\n",
            "          Conv2d-109            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-110            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-111            [-1, 512, 7, 7]               0\n",
            "          Conv2d-112            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-113            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-114            [-1, 512, 7, 7]               0\n",
            "      BasicBlock-115            [-1, 512, 7, 7]               0\n",
            "          Conv2d-116            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-117            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-118            [-1, 512, 7, 7]               0\n",
            "          Conv2d-119            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-120            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-121            [-1, 512, 7, 7]               0\n",
            "      BasicBlock-122            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
            "          Linear-124                 [-1, 1000]         513,000\n",
            "================================================================\n",
            "Total params: 21,797,672\n",
            "Trainable params: 21,797,672\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 96.29\n",
            "Params size (MB): 83.15\n",
            "Estimated Total Size (MB): 180.01\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for model in models_list:\n",
        "  summary(model, input_size=(3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYQZR1LDQ5NN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29ebedbe-160c-4f2c-caa8-c61e35ea0462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer:  conv1\n",
            "Writing to model  resnet\n",
            "Layer:  bn1\n",
            "Writing to model  resnet\n",
            "Layer:  relu\n",
            "Writing to model  resnet\n",
            "Layer:  maxpool\n",
            "Writing to model  resnet\n",
            "Layer:  layer1\n",
            "Writing to model  resnet\n",
            "Layer:  layer2\n",
            "Writing to model  resnet\n",
            "Layer:  layer3\n",
            "Writing to model  resnet\n",
            "Layer:  layer4\n",
            "Writing to model  resnet\n",
            "Layer:  avgpool\n",
            "Writing to model  resnet\n",
            "Layer:  fc\n",
            "Writing to model  resnet\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for model in models_list:\n",
        "  for name,layer in model.named_children():\n",
        "    weights = list(layer.parameters())\n",
        "    print(\"Layer: \",name)\n",
        "    weights_path = \"/content/drive/MyDrive/Colab Notebooks/\" + model.name\n",
        "    if not os.path.isdir(weights_path):\n",
        "      os.makedirs(weights_path)\n",
        "    file_name = name + '_weights.csv'\n",
        "    with open(os.path.join(weights_path,file_name), \"w\") as csv_file:\n",
        "      print(\"Writing to model \", model.name)\n",
        "      csvwriter = csv.writer(csv_file)\n",
        "      csvwriter.writerow(weights)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}